{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "72shGWUR62e4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TuhLVkQ27eG4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2a6ZNjM07psp"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet'\n",
    "train_dir= '/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet/train_1'\n",
    "test_dir = '/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet/test_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HunlineoPnhm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c--AOdIgFCsl"
   },
   "outputs": [],
   "source": [
    "classes = ['with_mask','without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1mjObgsIFQhN"
   },
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "  os.makedirs(os.path.join(train_dir,cls))\n",
    "  os.makedirs(os.path.join(test_dir,cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rkHUnAx4FgoQ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet\\\\with_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[0;32m      2\u001b[0m   class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir,\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m   images \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(class_path)\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;66;03m# split the images\u001b[39;00m\n\u001b[0;32m      5\u001b[0m   train_images, test_images \u001b[38;5;241m=\u001b[39m train_test_split(images, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet\\\\with_mask'"
     ]
    }
   ],
   "source": [
    "for cls in classes:\n",
    "  class_path = os.path.join(data_dir,cls)\n",
    "  images = os.listdir(class_path)\n",
    "  # split the images\n",
    "  train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "  # move images to train test directories\n",
    "  for img in  train_images:\n",
    "    shutil.copy(os.path.join(class_path,img),os.path.join(train_dir,cls,img))\n",
    "  for img in test_images:\n",
    "    shutil.copy(os.path.join(class_path,img),os.path.join(test_dir,cls,img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq342bJIH-DM"
   },
   "source": [
    " # Load the Data Using ImageDataGenerator\n",
    "Now that the dataset is split, load it using ImageDataGenerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0xD1OBtHYyX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mcXiTuBH6Z8"
   },
   "outputs": [],
   "source": [
    "train_aug = ImageDataGenerator( rescale=1.0/255,  # Normalize pixel values\n",
    "    rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "test_aug = ImageDataGenerator(rescale=1.0/255) #only scaling for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psJj6pswIVFO",
    "outputId": "726b5f97-af6f-413d-d5b0-b05d5fc32499"
   },
   "outputs": [],
   "source": [
    "# generators\n",
    "\n",
    "train_gen = train_aug.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='binary')\n",
    "\n",
    "test_gen = test_aug.flow_from_directory(test_dir,target_size = (128,128),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ExwErADJG98"
   },
   "source": [
    "# build a basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tobuEn0dI7iE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUWcXS-vJTTG"
   },
   "outputs": [],
   "source": [
    "model_1 = Sequential([\n",
    "    Input(shape=(128,128,3)),\n",
    "    Conv2D(150,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(100,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(50,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fzFC0ygOw0w"
   },
   "outputs": [],
   "source": [
    "early_Stopping= EarlyStopping(monitor='val_loss',patience=3,verbose=1,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tyu0kMUNKMZ8",
    "outputId": "6db84c0b-f0d8-4e4a-d78f-aed59eda86ca"
   },
   "outputs": [],
   "source": [
    "hist = model_1.fit(train_gen,epochs=10,validation_data=test_gen,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZ_JCl5GPjeT"
   },
   "source": [
    "### lets build another model with some paramter tunings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxnLgEH0Kke9"
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Input(shape=(128,128,3)),\n",
    "    Conv2D(150,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(100,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(50,3,activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_2.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcE5aW6ZQTS9",
    "outputId": "f08cb2f5-a37d-48e0-cc16-ee35a566f9ae"
   },
   "outputs": [],
   "source": [
    "hist_2 = model_2.fit(train_gen,epochs=10,validation_data=test_gen,verbose=1,callbacks=[early_Stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Eux890gQqrB",
    "outputId": "d81181e5-843f-4eea-8460-801b3b16e36b"
   },
   "outputs": [],
   "source": [
    "hist_2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zg1aU1RkRMHa",
    "outputId": "a9f120b5-6d10-48c1-c9c8-79bb48ba90f7"
   },
   "outputs": [],
   "source": [
    "model_2.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQbVOS3sRfYk",
    "outputId": "702d2d5e-fccc-4099-8728-d9f676725890"
   },
   "outputs": [],
   "source": [
    "pred_cnn = model_2.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwJgLeooRkTY",
    "outputId": "e65c8fba-52bb-4a23-8a3c-ccf27fe1e556"
   },
   "outputs": [],
   "source": [
    "pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpN_Vd2gRmG4"
   },
   "outputs": [],
   "source": [
    "pred_model_2 = []\n",
    "\n",
    "for x in pred_cnn:\n",
    "  if x>0.5:\n",
    "    pred_model_2.append(1)\n",
    "  else:\n",
    "    pred_model_2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-TvaCQsiRuCM",
    "outputId": "ef3dfb96-a858-4b65-dc18-eb12199f0bb0"
   },
   "outputs": [],
   "source": [
    "pred_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "TFDkb9cRRvYq",
    "outputId": "7852dba9-1a0d-4ab1-83e3-f03558f628c6"
   },
   "outputs": [],
   "source": [
    "test_gen.class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeq9n7x6RyvG",
    "outputId": "aa5c32b3-2096-4cbc-8c5f-76447d3b95ed"
   },
   "outputs": [],
   "source": [
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqJZ2meeSCwA"
   },
   "source": [
    "## lets also use a transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZpNXwRzR1EB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCryihABSHe1",
    "outputId": "cfbed203-e4fd-4b39-8508-f9f6bacee370"
   },
   "outputs": [],
   "source": [
    "base_model= VGG16(weights='imagenet',include_top=False,input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l74oVEppSNOV"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model building using vgg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGSwpB59SQFb"
   },
   "outputs": [],
   "source": [
    "mode_vgg = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(200,activation='relu'),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "mode_vgg.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "OFxmawCfS7hl",
    "outputId": "3241b556-99e1-486f-9fc3-c14c2f0db407"
   },
   "outputs": [],
   "source": [
    "mode_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F03hcqDbS8_C",
    "outputId": "903235af-c988-4085-b3ba-7dab7acc9a75"
   },
   "outputs": [],
   "source": [
    "hist_vgg = mode_vgg.fit(train_gen,epochs=10,validation_data=test_gen,verbose=1,callbacks=[early_Stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS75uK40TDkC",
    "outputId": "919ab47f-e829-4d5b-9b0d-99c585353a2f"
   },
   "outputs": [],
   "source": [
    "hist_vgg.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "GSst8dLTcEqa",
    "outputId": "dfa3e779-7858-4524-d5b3-8c900c5f667c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(hist_vgg.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(hist_vgg.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(hist_vgg.history['loss'], label='Train Loss')\n",
    "plt.plot(hist_vgg.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBRMv9U_S5ed"
   },
   "source": [
    "# predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zy7BJ0AXSWvn",
    "outputId": "e3f89ae1-5505-46c4-b961-b73d1424ff05"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"/content/drive/MyDrive/Face_Mask_Detection_Dataset_MaskNet/test_1/with_mask/B005.jpg\"\n",
    "\n",
    "load_img = image.load_img(img_path,target_size=(128,128))\n",
    "\n",
    "img_array = image.img_to_array(load_img)/255\n",
    "\n",
    "img_array = np.expand_dims(img_array,0)\n",
    "\n",
    "predictions = mode_vgg.predict(img_array)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbQxGS71Thcs",
    "outputId": "99c93caa-29c1-4740-ad34-8b4819670a7e"
   },
   "outputs": [],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-Fiy2NxTnW7",
    "outputId": "be3a53fb-f61c-4c92-ced4-034b49477888"
   },
   "outputs": [],
   "source": [
    "if predictions[0][0]<0.5:\n",
    "  print('with mask')\n",
    "else:\n",
    "  print('without mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpuQqAqwUO1I"
   },
   "source": [
    "# save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CspNx6qUObW",
    "outputId": "b9d775cd-ad72-43a6-b6d2-d9ebf040f765"
   },
   "outputs": [],
   "source": [
    "mode_vgg.save('face_mask_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWhzPIeNUFof"
   },
   "source": [
    "# deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6razHlJUAmh",
    "outputId": "b9a307a1-8a0f-4945-8706-7ea661c8d7fa"
   },
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foCGrwLvUJUp"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUEaY2nPU5k-",
    "outputId": "42806deb-44da-4ec2-fa0a-a1016a1764a2"
   },
   "outputs": [],
   "source": [
    "# model_pred = load_model('face_mask_detection_model.h5')\n",
    "# labels =  {0: 'With Mask', 1: 'Without Mask'}\n",
    "# def predict(img):\n",
    "#   load_img = image.load_img(img,target_size=(128,128))\n",
    "\n",
    "#   img_array = image.img_to_array(load_img)/255\n",
    "\n",
    "#   img_array = np.expand_dims(img_array,0)\n",
    "\n",
    "\n",
    "#   prediction = model_pred.predict(img_array)\n",
    "\n",
    "#   if prediction[0][0]<0.5:\n",
    "#     return labels[0]\n",
    "#   else:\n",
    "#     return labels[1]\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the model globally\n",
    "model_pred = load_model('face_mask_detection_model.h5')\n",
    "labels = {0: 'With Mask', 1: 'Without Mask'}\n",
    "\n",
    "\n",
    "\n",
    "def predict_img(img):\n",
    "    try:\n",
    "        # If `img` is a PIL Image, use it directly; no need to load from path\n",
    "        img = img.resize((128, 128))  # Resize to model input size\n",
    "        img_array = image.img_to_array(img) / 255.0  # Normalize the image\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model_pred.predict(img_array)\n",
    "\n",
    "        # Map prediction to label\n",
    "        if prediction[0][0] < 0.5:\n",
    "            return labels[0]\n",
    "        else:\n",
    "            return labels[1]\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WQsz98QVqNG"
   },
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict_img,  # Function to call\n",
    "    inputs=gr.Image(type=\"pil\"),  # Input type (PIL image)\n",
    "    outputs=\"text\",  # Output type (text)\n",
    "    title=\"Face Mask Detection\",\n",
    "    description=\"Upload an image to detect if the person is wearing a mask or not.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "cd9OdaFvV53_",
    "outputId": "976baa20-f3ab-4232-f5dc-68390118da17"
   },
   "outputs": [],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTKy_JySV-Am"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
